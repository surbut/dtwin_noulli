{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Treatment Pattern Analysis\n",
    "\n",
    "This notebook demonstrates the complete pipeline combining:\n",
    "1. Age-matched feature building\n",
    "2. Observational pattern learning with matched controls\n",
    "3. Bayesian propensity-response modeling\n",
    "\n",
    "Author: Sarah Urbut  \n",
    "Date: 2025-07-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Load your signature data, patient IDs, prescription data, and covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data here - adjust paths as needed\n",
    "# Example:\n",
    "# thetas = np.load('path/to/your/signature_loadings.npy')  # N x K x T\n",
    "# processed_ids = np.load('path/to/your/processed_ids.npy')\n",
    "# statins = pd.read_csv('path/to/your/statin_prescriptions.csv')\n",
    "# cov = pd.read_csv('path/to/your/covariates.csv')\n",
    "\n",
    "# For this example, assuming you already have these loaded:\n",
    "# thetas, processed_ids, statins, cov\n",
    "\n",
    "print(f\"Signature data shape: {thetas.shape}\")\n",
    "print(f\"Number of processed patients: {len(processed_ids)}\")\n",
    "print(f\"Number of prescription records: {len(statins)}\")\n",
    "print(f\"Number of patients with covariates: {len(cov)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean and Prepare Statin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the statin data - remove non-statins\n",
    "true_statins = statins[statins['drug_name'].str.contains(\n",
    "    'simvastatin|atorvastatin|rosuvastatin|pravastatin|fluvastatin|lovastatin', \n",
    "    case=False, na=False\n",
    ")].copy()\n",
    "\n",
    "print(f\"Total prescription records: {len(statins)}\")\n",
    "print(f\"True statins after filtering: {len(true_statins)}\")\n",
    "print(f\"Unique patients with true statins: {true_statins['eid'].nunique()}\")\n",
    "\n",
    "# Show distribution of statin types\n",
    "if len(true_statins) > 0:\n",
    "    statin_counts = true_statins['drug_name'].value_counts().head(10)\n",
    "    print(\"\\nTop 10 statin types:\")\n",
    "    print(statin_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Covariate Dictionary for Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create covariate dictionary for matching\n",
    "covariate_dicts = {}\n",
    "\n",
    "# Add age information\n",
    "if 'birth_year' in cov.columns:\n",
    "    current_year = 2025  # Adjust as needed\n",
    "    covariate_dicts['age'] = dict(zip(cov['eid'], current_year - cov['birth_year']))\n",
    "    print(f\"Added age information for {len(covariate_dicts['age'])} patients\")\n",
    "\n",
    "# Add sex information if available\n",
    "if 'sex' in cov.columns:\n",
    "    covariate_dicts['sex'] = dict(zip(cov['eid'], cov['sex']))\n",
    "    print(f\"Added sex information for {len(covariate_dicts['sex'])} patients\")\n",
    "\n",
    "# Add other covariates as needed\n",
    "# Example: BMI, smoking status, etc.\n",
    "# if 'bmi' in cov.columns:\n",
    "#     covariate_dicts['bmi'] = dict(zip(cov['eid'], cov['bmi']))\n",
    "\n",
    "print(f\"\\nCovariate dictionary keys: {list(covariate_dicts.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Comprehensive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the comprehensive analysis module\n",
    "from scripts.comprehensive_treatment_analysis import run_comprehensive_analysis\n",
    "\n",
    "# Optional: specify which signatures to use (None = use all)\n",
    "sig_indices = None  # or list(range(10)) for first 10 signatures\n",
    "\n",
    "# Optional: provide outcome data for Bayesian analysis\n",
    "# outcomes = your_outcome_data  # Binary outcomes for treated patients\n",
    "outcomes = None  # Set to None if no outcome data available\n",
    "\n",
    "print(\"Starting comprehensive analysis...\")\n",
    "print(\"This may take several minutes depending on data size.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete analysis\n",
    "results = run_comprehensive_analysis(\n",
    "    signature_loadings=thetas,\n",
    "    processed_ids=processed_ids,\n",
    "    statin_prescriptions=true_statins,\n",
    "    covariates=cov,\n",
    "    covariate_dicts=covariate_dicts,\n",
    "    sig_indices=sig_indices,\n",
    "    outcomes=outcomes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Examine Results\n",
    "\n",
    "### 5.1 Matching Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check matching results\n",
    "n_matched = len(results['matched_treated_indices'])\n",
    "print(f\"Successfully matched {n_matched} treated-control pairs\")\n",
    "\n",
    "# If we have age data, compare age distributions\n",
    "if 'age' in covariate_dicts:\n",
    "    treated_ages = [covariate_dicts['age'].get(eid, np.nan) \n",
    "                   for eid in results['enhanced_learner'].treatment_patterns['treated_patients']]\n",
    "    treated_ages = [age for age in treated_ages if not np.isnan(age)]\n",
    "    \n",
    "    if len(treated_ages) > 0:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(treated_ages, bins=20, alpha=0.7, label='Treated patients', density=True)\n",
    "        plt.xlabel('Age')\n",
    "        plt.ylabel('Density')\n",
    "        plt.title('Age Distribution of Treated Patients')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Mean age of treated patients: {np.mean(treated_ages):.1f} Â± {np.std(treated_ages):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Treatment Pattern Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine clustering results\n",
    "cluster_analysis = results['cluster_analysis']\n",
    "\n",
    "if cluster_analysis is not None:\n",
    "    print(\"Pre-treatment signature clusters:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for cluster_id, pattern in cluster_analysis['cluster_patterns'].items():\n",
    "        print(f\"Cluster {cluster_id}:\")\n",
    "        print(f\"  - {pattern['n_patients']} patients\")\n",
    "        print(f\"  - Mean treatment age: {pattern['mean_treatment_age']:.1f} years\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No clustering results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Treatment Readiness Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine treatment readiness patterns\n",
    "responsive_patterns = results['responsive_patterns']\n",
    "\n",
    "if responsive_patterns is not None:\n",
    "    readiness_sigs = responsive_patterns['treatment_readiness_signatures']\n",
    "    \n",
    "    print(\"Top 10 treatment readiness signatures:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Signature':<10} {'Readiness Score':<15} {'Trend Fraction':<15} {'Accel Fraction'}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, (sig_idx, score) in enumerate(readiness_sigs[:10]):\n",
    "        concerning = responsive_patterns['concerning_patterns'][sig_idx]\n",
    "        trend_frac = concerning['concerning_trend_fraction']\n",
    "        accel_frac = concerning['accelerating_fraction']\n",
    "        \n",
    "        print(f\"{sig_idx:<10} {score:<15.3f} {trend_frac:<15.3f} {accel_frac:<15.3f}\")\n",
    "else:\n",
    "    print(\"No responsive patterns available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Matched Control Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine treated vs matched control differences\n",
    "matched_comparison = results['matched_comparison']\n",
    "\n",
    "if matched_comparison is not None:\n",
    "    print(\"Treated vs Matched Controls (Top 10 signatures by effect size):\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Sig':<4} {'Treated':<10} {'Control':<10} {'Difference':<12} {'Effect Size':<12} {'P-value':<10} {'Sig?'}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Sort by absolute effect size\n",
    "    sorted_sigs = sorted(matched_comparison.items(), \n",
    "                        key=lambda x: abs(x[1]['effect_size']), reverse=True)\n",
    "    \n",
    "    for sig_idx, stats in sorted_sigs[:10]:\n",
    "        sig_marker = \"***\" if stats['p_value'] < 0.05 else \"\"\n",
    "        print(f\"{sig_idx:<4} {stats['treated_mean']:<10.4f} {stats['control_mean']:<10.4f} \"\n",
    "              f\"{stats['difference']:<12.4f} {stats['effect_size']:<12.4f} \"\n",
    "              f\"{stats['p_value']:<10.4f} {sig_marker}\")\n",
    "else:\n",
    "    print(\"No matched comparison results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Prediction Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine prediction model results\n",
    "predictor = results['predictor']\n",
    "\n",
    "if predictor is not None:\n",
    "    print(f\"Treatment Readiness Prediction Model:\")\n",
    "    print(f\"Cross-validation AUC: {predictor['cv_auc']:.3f}\")\n",
    "    \n",
    "    # Feature importance from Random Forest\n",
    "    if hasattr(predictor['model'], 'feature_importances_'):\n",
    "        importances = predictor['model'].feature_importances_\n",
    "        n_features_per_sig = 4  # trend, level, level_vs_typical, accel\n",
    "        n_signatures = len(importances) // n_features_per_sig\n",
    "        \n",
    "        # Aggregate importance by signature\n",
    "        sig_importances = []\n",
    "        for s in range(n_signatures):\n",
    "            start_idx = s * n_features_per_sig\n",
    "            end_idx = start_idx + n_features_per_sig\n",
    "            sig_importance = np.sum(importances[start_idx:end_idx])\n",
    "            sig_importances.append((s, sig_importance))\n",
    "        \n",
    "        # Sort by importance\n",
    "        sig_importances.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(\"\\nTop 10 most important signatures for prediction:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"{'Signature':<10} {'Importance':<12}\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        for sig_idx, importance in sig_importances[:10]:\n",
    "            print(f\"{sig_idx:<10} {importance:<12.4f}\")\n",
    "else:\n",
    "    print(\"No prediction model results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Bayesian Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine Bayesian analysis results\n",
    "trace = results['bayesian_trace']\n",
    "bayesian_model = results['bayesian_model']\n",
    "\n",
    "if trace is not None:\n",
    "    print(\"Bayesian Propensity-Response Analysis:\")\n",
    "    print(f\"Number of chains: {len(trace.posterior.chain)}\")\n",
    "    print(f\"Number of draws per chain: {len(trace.posterior.draw)}\")\n",
    "    \n",
    "    # Plot trace for key parameters\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # Propensity baseline\n",
    "    az.plot_trace(trace, var_names=['propensity_baseline'], ax=axes[0, :])\n",
    "    axes[0, 0].set_title('Propensity Baseline (Trace)')\n",
    "    axes[0, 1].set_title('Propensity Baseline (Posterior)')\n",
    "    \n",
    "    # Treatment effect (if available)\n",
    "    if 'treatment_effect' in trace.posterior:\n",
    "        az.plot_trace(trace, var_names=['treatment_effect'], ax=axes[1, :])\n",
    "        axes[1, 0].set_title('Treatment Effect (Trace)')\n",
    "        axes[1, 1].set_title('Treatment Effect (Posterior)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nPosterior Summary:\")\n",
    "    print(az.summary(trace, var_names=['propensity_baseline']))\n",
    "    \n",
    "    if 'treatment_effect' in trace.posterior:\n",
    "        print(\"\\nTreatment Effect Summary:\")\n",
    "        print(az.summary(trace, var_names=['treatment_effect']))\n",
    "        \n",
    "else:\n",
    "    print(\"No Bayesian analysis results available\")\n",
    "    print(\"This may be due to insufficient data or computational issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Visualizations\n",
    "\n",
    "### 6.1 Signature Comparison Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of signature differences\n",
    "if matched_comparison is not None:\n",
    "    # Extract data for heatmap\n",
    "    signatures = list(matched_comparison.keys())\n",
    "    differences = [matched_comparison[s]['difference'] for s in signatures]\n",
    "    p_values = [matched_comparison[s]['p_value'] for s in signatures]\n",
    "    \n",
    "    # Create significance mask\n",
    "    significant = np.array(p_values) < 0.05\n",
    "    \n",
    "    # Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Differences\n",
    "    diff_matrix = np.array(differences).reshape(-1, 1)\n",
    "    im1 = ax1.imshow(diff_matrix.T, cmap='RdBu_r', aspect='auto')\n",
    "    ax1.set_title('Signature Differences (Treated - Control)')\n",
    "    ax1.set_xlabel('Signature Index')\n",
    "    ax1.set_xticks(range(0, len(signatures), max(1, len(signatures)//10)))\n",
    "    ax1.set_xticklabels([str(signatures[i]) for i in range(0, len(signatures), max(1, len(signatures)//10))])\n",
    "    ax1.set_yticks([])\n",
    "    plt.colorbar(im1, ax=ax1)\n",
    "    \n",
    "    # Significance\n",
    "    sig_matrix = significant.astype(int).reshape(-1, 1)\n",
    "    im2 = ax2.imshow(sig_matrix.T, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)\n",
    "    ax2.set_title('Statistical Significance (p < 0.05)')\n",
    "    ax2.set_xlabel('Signature Index')\n",
    "    ax2.set_xticks(range(0, len(signatures), max(1, len(signatures)//10)))\n",
    "    ax2.set_xticklabels([str(signatures[i]) for i in range(0, len(signatures), max(1, len(signatures)//10))])\n",
    "    ax2.set_yticks([])\n",
    "    plt.colorbar(im2, ax=ax2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Number of significantly different signatures: {np.sum(significant)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Treatment Timing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze treatment timing patterns\n",
    "learner = results['enhanced_learner']\n",
    "treatment_times = np.array(learner.treatment_patterns['treatment_times'])\n",
    "treatment_ages = treatment_times + learner.time_start_age\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Treatment age distribution\n",
    "axes[0].hist(treatment_ages, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Age at Treatment Initiation')\n",
    "axes[0].set_ylabel('Number of Patients')\n",
    "axes[0].set_title('Treatment Initiation Age Distribution')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axvline(np.median(treatment_ages), color='red', linestyle='--', \n",
    "                label=f'Median: {np.median(treatment_ages):.1f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Treatment by year (if prescription dates available)\n",
    "if 'issue_date' in true_statins.columns:\n",
    "    true_statins['year'] = pd.to_datetime(true_statins['issue_date'], \n",
    "                                         format='%d/%m/%Y', errors='coerce').dt.year\n",
    "    year_counts = true_statins.groupby('year').size()\n",
    "    \n",
    "    axes[1].plot(year_counts.index, year_counts.values, marker='o')\n",
    "    axes[1].set_xlabel('Year')\n",
    "    axes[1].set_ylabel('Number of Prescriptions')\n",
    "    axes[1].set_title('Statin Prescriptions Over Time')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Age vs cluster assignment (if clustering available)\n",
    "if cluster_analysis is not None:\n",
    "    clusters = cluster_analysis['clusters']\n",
    "    unique_clusters = np.unique(clusters)\n",
    "    \n",
    "    for cluster_id in unique_clusters:\n",
    "        cluster_mask = clusters == cluster_id\n",
    "        cluster_ages = treatment_ages[cluster_mask]\n",
    "        axes[2].hist(cluster_ages, alpha=0.6, label=f'Cluster {cluster_id}', bins=15)\n",
    "    \n",
    "    axes[2].set_xlabel('Age at Treatment')\n",
    "    axes[2].set_ylabel('Number of Patients')\n",
    "    axes[2].set_title('Treatment Age by Cluster')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Matching summary\n",
    "n_matched = len(results['matched_treated_indices'])\n",
    "print(f\"\\n1. MATCHING RESULTS:\")\n",
    "print(f\"   - Successfully matched {n_matched} treated-control pairs\")\n",
    "print(f\"   - Matching controlled for age and other available covariates\")\n",
    "\n",
    "# Pattern discovery summary\n",
    "if cluster_analysis is not None:\n",
    "    n_clusters = cluster_analysis['n_clusters']\n",
    "    print(f\"\\n2. PATTERN DISCOVERY:\")\n",
    "    print(f\"   - Identified {n_clusters} distinct pre-treatment signature patterns\")\n",
    "    \n",
    "    for cluster_id, pattern in cluster_analysis['cluster_patterns'].items():\n",
    "        print(f\"   - Cluster {cluster_id}: {pattern['n_patients']} patients, \"\n",
    "              f\"avg age {pattern['mean_treatment_age']:.1f}\")\n",
    "\n",
    "# Signature differences summary\n",
    "if matched_comparison is not None:\n",
    "    significant_sigs = [s for s, stats in matched_comparison.items() \n",
    "                       if stats['p_value'] < 0.05]\n",
    "    print(f\"\\n3. SIGNATURE DIFFERENCES (Treated vs Matched Controls):\")\n",
    "    print(f\"   - {len(significant_sigs)} signatures show significant differences (p < 0.05)\")\n",
    "    \n",
    "    if len(significant_sigs) > 0:\n",
    "        top_sig = max(matched_comparison.items(), \n",
    "                     key=lambda x: abs(x[1]['effect_size']))\n",
    "        print(f\"   - Strongest effect: Signature {top_sig[0]} \"\n",
    "              f\"(effect size = {top_sig[1]['effect_size']:.3f})\")\n",
    "\n",
    "# Prediction performance\n",
    "if predictor is not None:\n",
    "    print(f\"\\n4. PREDICTION MODEL:\")\n",
    "    print(f\"   - Treatment readiness model AUC: {predictor['cv_auc']:.3f}\")\n",
    "    \n",
    "    if predictor['cv_auc'] > 0.7:\n",
    "        print(f\"   - Model shows good predictive performance\")\n",
    "    elif predictor['cv_auc'] > 0.6:\n",
    "        print(f\"   - Model shows moderate predictive performance\")\n",
    "    else:\n",
    "        print(f\"   - Model shows limited predictive performance\")\n",
    "\n",
    "# Bayesian analysis summary\n",
    "if trace is not None:\n",
    "    print(f\"\\n5. BAYESIAN CAUSAL INFERENCE:\")\n",
    "    print(f\"   - Successfully completed propensity-response modeling\")\n",
    "    print(f\"   - {len(trace.posterior.chain)} chains, \"\n",
    "          f\"{len(trace.posterior.draw)} draws per chain\")\n",
    "    \n",
    "    if 'treatment_effect' in trace.posterior:\n",
    "        treatment_effect_mean = float(trace.posterior['treatment_effect'].mean())\n",
    "        print(f\"   - Estimated treatment effect: {treatment_effect_mean:.3f}\")\n",
    "else:\n",
    "    print(f\"\\n5. BAYESIAN CAUSAL INFERENCE:\")\n",
    "    print(f\"   - Analysis not completed (may need outcome data)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save key results to files\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamp for filenames\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save results dictionary\n",
    "output_file = f\"comprehensive_analysis_results_{timestamp}.pkl\"\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "print(f\"Results saved to: {output_file}\")\n",
    "\n",
    "# Save summary statistics to CSV\n",
    "if matched_comparison is not None:\n",
    "    comparison_df = pd.DataFrame(matched_comparison).T\n",
    "    comparison_df.to_csv(f\"signature_comparison_{timestamp}.csv\")\n",
    "    print(f\"Signature comparison saved to: signature_comparison_{timestamp}.csv\")\n",
    "\n",
    "# Save Bayesian results if available\n",
    "if trace is not None:\n",
    "    az.to_netcdf(trace, f\"bayesian_trace_{timestamp}.nc\")\n",
    "    print(f\"Bayesian trace saved to: bayesian_trace_{timestamp}.nc\")\n",
    "\n",
    "print(\"\\nAll results saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}